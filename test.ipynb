{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soufiane/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "from numpy.linalg import inv\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys \n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from numpy.linalg import inv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.externals.joblib import dump\n",
    "from sklearn import model_selection \n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score,StratifiedKFold, learning_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import validation_curve,ShuffleSplit\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.ensemble import RandomForestRegressor,  RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, Matern\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from utils import *\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('5760_simple_discriptors-SMILES.xlsx')\n",
    "data = df.drop([ 'Reaction_No', 'SMILES', 'Catalyst_1_Short_Hand','SMILES_R1','SMILES_R2','SMILES','SMILES_LI','SMILES_BASE','SMILES_SOLV'], axis=1 )\n",
    "data_used = data.dropna(axis=0 , how='any')\n",
    "\n",
    "# dropping missed values\n",
    "data_used = data_used.reset_index().drop('index', axis=1).copy()\n",
    "\n",
    "# Normalization of continuous variables \n",
    "data_used['Product_Yield_PCT_Area_UV'] = data_used['Product_Yield_PCT_Area_UV']\n",
    "\n",
    "xls = pd.ExcelFile('Descriptors for Computational Modelling.xlsx')\n",
    "df_Bases = pd.read_excel(xls, 'Base_Short_Hand')\n",
    "df_Solvents = pd.read_excel(xls, 'Solvent_1_Short_Hand')\n",
    "df_Ligands = pd.read_excel(xls, 'Ligand_Short_Hand')\n",
    "\n",
    "# one hot encoding\n",
    "data_ohe = data_cleaning(data_used)\n",
    "Y_ohe = data_ohe[\"Product_Yield_PCT_Area_UV\"]\n",
    "data_ohe = data_ohe.drop('Product_Yield_PCT_Area_UV', axis=1)\n",
    "X_ohe = pd.get_dummies(data_ohe)\n",
    "\n",
    "# discreptors\n",
    "df_descr = data_discreptors(data_used,xls,df_Ligands,df_Bases,df_Solvents)\n",
    "Y_just_descri = df_descr[\"Product_Yield_PCT_Area_UV\"]\n",
    "df = df_descr.drop(['Product_Yield_PCT_Area_UV',\"Ligand_Short_Hand\",\"Base_Short_Hand\",\"Solvent_1_Short_Hand\"], axis=1)\n",
    "X_just_descri = pd.get_dummies(df)\n",
    "df_descr = X_just_descri.copy()\n",
    "df_descr[\"Product_Yield_PCT_Area_UV\"] = Y_just_descri.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_models(X_train, \n",
    "               X_test,\n",
    "               y_train, \n",
    "               y_test,\n",
    "               models=[]):\n",
    "    predictions = []\n",
    "    r2_values = []\n",
    "    rmse_values = []\n",
    "    for model in models:\n",
    "        #print(model)\n",
    "        # fit the model and generate predictions\n",
    "        model.fit(X_train, y_train.ravel())\n",
    "        preds = model.predict(X_test)\n",
    "\n",
    "        # calculate an R-squared and RMSE values\n",
    "        r_squared = r2_score(y_test, preds)\n",
    "        rmse = mean_squared_error(y_test, preds) ** 0.5\n",
    "\n",
    "        # append all to lists\n",
    "        predictions.append(preds)\n",
    "        r2_values.append(r_squared)\n",
    "        rmse_values.append(rmse)\n",
    "    #print('Done fitting models')\n",
    "    return predictions, r2_values, rmse_values\n",
    "\n",
    "def Have_Same_Node_At(tree,x1,x2,h):        \n",
    "    t1 = tree.decision_path(x1, check_input=True).toarray()[0][h]\n",
    "    t2 = tree.decision_path(x2, check_input=True).toarray()[0][h]\n",
    "    return int(t1 == t2) \n",
    "    \n",
    "    \n",
    "    \n",
    "def Kernel_Function(F,x1, x2):\n",
    "    sum = 0\n",
    "    for tree in F.estimators_:\n",
    "        max_height = tree.tree_.node_count\n",
    "        h = np.random.randint(max_height)\n",
    "        if (Have_Same_Node_At(tree,x1,x2,h) == 1):\n",
    "            sum = sum +1\n",
    "    return sum/len(F.estimators_)\n",
    "\n",
    "    \n",
    "def Kernel_Function_2(F,x1, x2):\n",
    "    SUM = 0\n",
    "    K = 100  #num simulations\n",
    "    for tree in F.estimators_:\n",
    "        max_height = tree.tree_.node_count\n",
    "        \n",
    "        sum = 0\n",
    "        for k in range(K):\n",
    "            h = np.random.randint(max_height)           \n",
    "            if (Have_Same_Node_At(tree,x1,x2,h) == 1):\n",
    "                sum = sum +1\n",
    "        sum = sum/K\n",
    "            \n",
    "                \n",
    "        SUM = SUM + sum    \n",
    "    return sum/len(F.estimators_)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def to_naive_encoding(df):\n",
    "    df_numpy = df.to_numpy()\n",
    "    df_np = np.argmax(df_numpy, axis = 1)\n",
    "    return df_np\n",
    "\n",
    "\n",
    "\n",
    "def index_to_tuple(index):\n",
    "     return dictionary[index]\n",
    "     \n",
    "\n",
    "def compute_kernel_smart(index):\n",
    "    (i,j) = index_to_tuple(index)\n",
    "    x1 = X_just_descri.iloc[i].values.reshape(1, -1)\n",
    "    x2 = X_just_descri.iloc[j].values.reshape(1, -1)\n",
    "    return Kernel_Function_2(model, x1, x2)\n",
    "\n",
    "\n",
    "\n",
    "def kernel_matrix(model, X_train_test): \n",
    "    n = X_train_test.shape[0]\n",
    "    N = int(n*(n+1)/2)\n",
    "    keys = range(N)\n",
    "    values  = [ (a,b) for a in range(n) for b in range(a+1)]\n",
    "    global dictionary\n",
    "    dictionary = dict(zip(keys, values))\n",
    "    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    matrix = np.zeros((X_train_test.shape[0], X_train_test.shape[0]))\n",
    "    p = Pool()\n",
    "    #result = p.map(compute_kernel_smart, keys)\n",
    "    result = p.map(getattr(sys.modules[__name__], \"compute_kernel_smart\"), keys)\n",
    "\n",
    "    p.close()\n",
    "    p.join()\n",
    "    end_time = (time.time() - start_time)/60\n",
    "    \n",
    "    print(f\"Processing took {end_time} min time using multiprocessing.\")\n",
    "    output = [x for x in result]\n",
    "    \n",
    "    matrix = np.zeros((X_train_test.shape[0], X_train_test.shape[0]))\n",
    "    \n",
    "    for index in range(N):\n",
    "        (i,j) = dictionary[index]\n",
    "        matrix[i,j] = output[index]\n",
    "        matrix[j,i] = output[index]\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def posterior_predictive(model,X_test, X_train, y_train, sigma_y=1e-2):\n",
    "    \n",
    "    X  =  X_train.copy()\n",
    "    X  =  X.append(X_test) \n",
    "\n",
    "    Kernel_mat = kernel_matrix(model, X)\n",
    "    error = min(np.linalg.eigvals(Kernel_mat))\n",
    "    # semi_def_pos_kernel = laplacian(Kernel_mat, normed=True)\n",
    "    \n",
    "    \n",
    "    df_kernel = pd.DataFrame(data=Kernel_mat, index=X.index,  columns = X.index)\n",
    "    \n",
    "    K = df_kernel.loc[X_train.index,X_train.index] +  (sigma_y**2  + abs(error) )* np.eye(len(X_train))\n",
    "    #K = df_kernel.loc[X_train.index,X_train.index] +  (sigma_y**2 )*np.eye(len(X_train))\n",
    "    K_s = df_kernel.loc[X_train.index,:].loc[:,X_test.index]\n",
    "    K_ss = df_kernel.loc[X_test.index, X_test.index] + 1e-8 * np.eye(len(X_test))\n",
    "    K_inv = inv(K)\n",
    "    \n",
    "\n",
    "    mu_s = K_s.T.dot(K_inv).dot(y_train.values)\n",
    "    var_s = K_ss \n",
    "    \n",
    "    return mu_s, var_s\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_models(predictions,\n",
    "                r2_values,\n",
    "                rmse_values,\n",
    "                y_test,\n",
    "                titles = ['Gaussian process with Random Forest kernel'],\n",
    "                save=False):\n",
    "\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    for pred, r2, rmse, title in zip( predictions,\n",
    "                                      r2_values,\n",
    "                                      rmse_values,\n",
    "                                      titles):\n",
    "        # create subplot\n",
    "        plt.subplot()\n",
    "        plt.grid(alpha=0.2)\n",
    "        plt.title(title, fontsize=15)\n",
    "        \n",
    "        # add score patches\n",
    "        r2_patch = mpatches.Patch(label=\"R2 = {:04.2f}\".format(r2))\n",
    "        rmse_patch = mpatches.Patch(label=\"RMSE = {:04.1f}\".format(rmse))\n",
    "        plt.scatter(pred, y_test.values, alpha=0.2)\n",
    "        plt.legend(handles=[r2_patch, rmse_patch], fontsize=12)\n",
    "        plt.plot(np.arange(2), np.arange(2), ls=\"--\", c=\".3\")\n",
    "        fig.text(0.5, 0.08, 'predicted yield', ha='center', va='center', fontsize=15)\n",
    "        fig.text(0.09, 0.5, 'observed yield', ha='center', va='center', rotation='vertical', fontsize=15)\n",
    "    if save:\n",
    "        plt.savefig(save, dpi = 300)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def fit_GP_RF_kernel(X_train, \n",
    "               X_test,\n",
    "               y_train, \n",
    "               y_test,\n",
    "               model ):\n",
    "\n",
    "    # calculate the posterior predictive of GP with RF kernel the model and generate predictions for X_test\n",
    "    \n",
    "    mu_s, var_s = posterior_predictive(model,X_test, X_train, y_train, sigma_y = 1e-2)\n",
    "    preds = mu_s.loc[X_test.index]\n",
    "    \n",
    "    # calculate an R-squared and RMSE values\n",
    "    r_squared = r2_score(y_test, preds)\n",
    "    rmse = mean_squared_error(y_test, preds) ** 0.5\n",
    "\n",
    "\n",
    "    return preds, r_squared, rmse    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_just_descri_normal = (Y_just_descri - np.mean(Y_just_descri))/ np.linalg.norm(Y_just_descri)\n",
    "\n",
    "X_train, X_test,y_train, y_test = train_test_split(X_just_descri.head(10), Y_just_descri_normal.head(10), train_size=0.8, random_state = 2) \n",
    "\n",
    "models = [RandomForestRegressor(n_estimators=5)]\n",
    "preds, r2_values, rmse_values  = fit_models(X_train,\n",
    "                                            X_test,\n",
    "                                            y_train,\n",
    "                                            y_test,\n",
    "                                            models)\n",
    "model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing took 0.25166289806365966 min time using multiprocessing.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6    0.012757\n",
       " 1   -0.007892\n",
       " dtype: float64,        6      1\n",
       " 6  0.200  0.104\n",
       " 1  0.104  0.200)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_predictive(model,X_test, X_train, y_train, sigma_y = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
