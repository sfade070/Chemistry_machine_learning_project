{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comparing : \n",
    "\n",
    "* labmate Ai \n",
    "* Bayesien Optimization approch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/NOBACKUP/natika/mypython/lib/python3.7/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys \n",
    "import time\n",
    "import random\n",
    "import time\n",
    "from numpy.linalg import inv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.externals.joblib import dump\n",
    "from sklearn import model_selection \n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score,StratifiedKFold, learning_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import validation_curve,ShuffleSplit\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.ensemble import RandomForestRegressor,  RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, Matern\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from utils import *\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('5760_simple_discriptors-SMILES.xlsx')\n",
    "data = df.drop([ 'Reaction_No', 'SMILES', 'Catalyst_1_Short_Hand','SMILES_R1','SMILES_R2','SMILES','SMILES_LI','SMILES_BASE','SMILES_SOLV'], axis=1 )\n",
    "data_used = data.dropna(axis=0 , how='any')\n",
    "\n",
    "# dropping missed values\n",
    "data_used = data_used.reset_index().drop('index', axis=1).copy()\n",
    "\n",
    "# Normalization of continuous variables \n",
    "data_used['Product_Yield_PCT_Area_UV'] = data_used['Product_Yield_PCT_Area_UV']/100\n",
    "\n",
    "xls = pd.ExcelFile('Descriptors for Computational Modelling.xlsx')\n",
    "df_Bases = pd.read_excel(xls, 'Base_Short_Hand')\n",
    "df_Solvents = pd.read_excel(xls, 'Solvent_1_Short_Hand')\n",
    "df_Ligands = pd.read_excel(xls, 'Ligand_Short_Hand')\n",
    "\n",
    "# one hot encoding\n",
    "data_ohe = data_cleaning(data_used)\n",
    "Y_ohe = data_ohe[\"Product_Yield_PCT_Area_UV\"]\n",
    "data_ohe = data_ohe.drop('Product_Yield_PCT_Area_UV', axis=1)\n",
    "X_ohe = pd.get_dummies(data_ohe)\n",
    "data_ohe = X_ohe.copy()\n",
    "data_ohe[\"Product_Yield_PCT_Area_UV\"] = Y_ohe.copy()\n",
    "\n",
    "# discreptors\n",
    "df_descr = data_discreptors(data_used,xls,df_Ligands,df_Bases,df_Solvents)\n",
    "Y_just_descri = df_descr[\"Product_Yield_PCT_Area_UV\"]\n",
    "df = df_descr.drop(['Product_Yield_PCT_Area_UV',\"Ligand_Short_Hand\",\"Base_Short_Hand\",\"Solvent_1_Short_Hand\"], axis=1)\n",
    "X_just_descri = pd.get_dummies(df)\n",
    "df_descr = X_just_descri.copy()\n",
    "df_descr[\"Product_Yield_PCT_Area_UV\"] = Y_just_descri.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3304, 26)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_descr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aquisition functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  cross_validations_plots(model,X,Y,n_splits = 4):\n",
    "     \n",
    "    #CV = [KFold,ShuffleSplit]\n",
    "    CV = [ShuffleSplit]\n",
    "    cv_results = []\n",
    "    n_splits = 4\n",
    "    for cv in CV :\n",
    "        this_cv = cv(n_splits=n_splits)\n",
    "        result = -cross_val_score(model, X, Y, cv=this_cv, scoring='neg_root_mean_squared_error') \n",
    "        cv_results.append(result)        \n",
    "        \n",
    "    cv_means = []\n",
    "    cv_std = []\n",
    "    for cv_result in cv_results:\n",
    "        cv_means.append(cv_result.mean())\n",
    "        cv_std.append(cv_result.std())\n",
    "\n",
    "    cv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\"Algorithm\":[\"ShuffleSplit\"]})\n",
    "    return cv_res\n",
    "\n",
    "def expected_improvement_RF(model,X_unseen,X_train,y_train,xi=0.1):\n",
    "    model.fit(X_train,y_train)\n",
    "    dim = X_train.shape[1]\n",
    "    \n",
    "    all_predictions = []\n",
    "    for e in model.estimators_:\n",
    "        #print(X_unseen.shape)\n",
    "        #print(X_train.shape)\n",
    "        all_predictions += [e.predict(X_unseen)]\n",
    "    \n",
    "    variance = np.var(all_predictions, axis=0)\n",
    "    sigma = np.sqrt(variance)\n",
    "    mu = model.predict(X_unseen) \n",
    "    mu_sample = model.predict(X_train) \n",
    "    \n",
    "    \n",
    "    sigma = sigma.reshape(-1, X_unseen.shape[0])\n",
    "    \n",
    "    mu_sample_opt = np.max(mu_sample) \n",
    "\n",
    "    with np.errstate(divide='warn'): \n",
    "        imp = mu - mu_sample_opt - xi \n",
    "        Z = imp / sigma \n",
    "        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z) \n",
    "        ei[sigma == 0.0] = 0.0 \n",
    "    \n",
    "    \n",
    "    ei_df = pd.DataFrame(data=ei.reshape(-1,ei.shape[0]), columns=['expected_improvement_RF'],index = X_unseen.index)  \n",
    "    predictions = model.predict(X_unseen)\n",
    "    predictions_df = pd.DataFrame(data=predictions, columns=['Prediction'],index = X_unseen.index)\n",
    "    assert len(ei_df) == len(predictions) # control line\n",
    "    initial_data = pd.DataFrame(data=X_unseen, columns = list(X_unseen.columns.values),index = X_unseen.index)\n",
    "    df = pd.concat([initial_data, predictions_df, ei_df], axis=1)\n",
    "    return df \n",
    "\n",
    "def probability_of_improvement(model,X_unseen,X_train,y_train):\n",
    "    model.fit(X_train,y_train)\n",
    "    dim = X_train.shape[1]\n",
    "    \n",
    "    all_predictions = []\n",
    "    for e in model.estimators_:\n",
    "        all_predictions += [e.predict(X_unseen)]\n",
    "    \n",
    "    variance = np.var(all_predictions, axis=0)\n",
    "    sigma = np.sqrt(variance)\n",
    "    \n",
    "    mu = model.predict(X_unseen) \n",
    "    mu_sample = model.predict(X_train) \n",
    "    \n",
    "    \n",
    "    sigma = sigma.reshape(-1, X_unseen.shape[0])\n",
    "    \n",
    "    mu_sample_opt = np.max(mu_sample) \n",
    "\n",
    "    with np.errstate(divide='warn'):          \n",
    "        pi = norm.cdf((mu - mu_sample_opt)/(sigma+1E-9)) \n",
    "    \n",
    "    \n",
    "    pi_df = pd.DataFrame(data=pi.reshape(-1,pi.shape[0]), columns=['probability_of_improvement'])  \n",
    "    predictions = model.predict(X_unseen)\n",
    "    predictions_df = pd.DataFrame(data=predictions, columns=['Prediction'])\n",
    "    assert len(pi_df) == len(predictions) # control line\n",
    "    #initial_data = pd.DataFrame(data=X_unseen, columns = list(X_unseen.columns.values))\n",
    "    #df = pd.concat([initial_data, predictions_df, pi_df], axis=1)\n",
    "    df = pd.concat([predictions_df, pi_df], axis=1)\n",
    "    return df\n",
    "\n",
    "# test \n",
    "#model = RandomForestRegressor(200)\n",
    "#X_train, X_test,y_train, y_test = train_test_split(X_just_descri, Y_just_descri, train_size=0.06, random_state = 2)\n",
    "#pi_values = probability_of_improvement(model,X_test,X_train,y_train).iloc[:100,-1]\n",
    "#plt.figure(figsize=(20,6))\n",
    "#plt.plot(ei_values,'or', label='Expected improvement')\n",
    "#plt.xlabel('Iteration')\n",
    "#plt.ylabel(' yield')\n",
    "#plt.legend()\n",
    "\n",
    "\n",
    "def upper_confidence_bound(model,X_unseen,X_train,y_train,beta = 0.1):\n",
    "    model.fit(X_train,y_train)\n",
    "    dim = X_train.shape[1]\n",
    "    \n",
    "    all_predictions = []\n",
    "    for e in model.estimators_:\n",
    "        all_predictions += [e.predict(X_unseen)]\n",
    "    \n",
    "    variance = np.var(all_predictions, axis=0)\n",
    "    sigma = np.sqrt(variance)\n",
    "    \n",
    "    mu = model.predict(X_unseen) \n",
    "    mu_sample = model.predict(X_train) \n",
    "    \n",
    "    \n",
    "    sigma = sigma.reshape(-1, X_unseen.shape[0])\n",
    "    \n",
    "    mu_sample_opt = np.max(mu_sample) \n",
    "\n",
    "    \n",
    "    ucb = mu - beta*sigma # where beta > 0 is a tradeoff paramete\n",
    "    \n",
    "    \n",
    "    ucb_df = pd.DataFrame(data=ucb.reshape(-1,ucb.shape[0]), columns=['upper_confidence_bound'])  \n",
    "    predictions = model.predict(X_unseen)\n",
    "    predictions_df = pd.DataFrame(data=predictions, columns=['Prediction'])\n",
    "    assert len(ucb_df) == len(predictions) # control line\n",
    "    #initial_data = pd.DataFrame(data=X_unseen, columns = list(X_unseen.columns.values))\n",
    "    #df = pd.concat([initial_data, predictions_df, pi_df], axis=1)\n",
    "    df = pd.concat([predictions_df, ucb_df], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining chemical space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Defining chemical space for simulating navigation of reaction space\n",
    "class ChemicalSpace():\n",
    "    ''' Abstract class of chemical space for simulating navigation of \n",
    "        reaction space using machine learning'''\n",
    "    \n",
    "    def __init__(self, df, seed=None):\n",
    "        # seed for reproduciibity\n",
    "        random.seed(seed)\n",
    "        self.df = df\n",
    "        self.index = list(df.index)\n",
    "        self.explored_space_index = []\n",
    "        self.space_len = len(self.index)\n",
    "        # randomize the indexes\n",
    "        random.shuffle(self.index)\n",
    "        \n",
    "        \n",
    "    def random_guess(self,number_initial_data):\n",
    "        '''Returns the dataframe with random rxns from chemical space'''\n",
    "        num_of_rxns = number_initial_data    \n",
    "        random_rxns_idxs = []        \n",
    "        for idx  in self.index:\n",
    "            if idx not in self.explored_space_index:\n",
    "                self.explored_space_index.append(idx)\n",
    "                random_rxns_idxs.append(idx)\n",
    "                if len(random_rxns_idxs) == num_of_rxns:\n",
    "                    break\n",
    "        random_df = self.df.loc[random_rxns_idxs]\n",
    "        return random_df\n",
    "    \n",
    "    \n",
    "    def get_unused(self):\n",
    "        ''' Return a dataframe of all reactions which has not been explored so far'''\n",
    "        \n",
    "        unused_rxn_idxs = []\n",
    "        \n",
    "        for idx in self.index:\n",
    "            if idx not in self.explored_space_index:\n",
    "                unused_rxn_idxs.append(idx)\n",
    "                \n",
    "        unused_rxns = self.df.loc[unused_rxn_idxs]\n",
    "        return unused_rxns\n",
    "        \n",
    "    def get_explored(self):\n",
    "        ''' Return a dataframe with indexes of reactions which have been chosen'''\n",
    "        \n",
    "        return self.df.loc[self.explored_space_index]\n",
    "    \n",
    "    def update_explored_rxns(self, rxn_idxs):\n",
    "        ''' Add rxn_idxs to the list of explored reactions'''\n",
    "        self.explored_space_index += rxn_idxs\n",
    "        \n",
    "    def is_empty(self):\n",
    "        ''' Return True if the whole chemical space has been explored'''\n",
    "        if len(self.explored_space_index) == self.space_len:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def percent_explored(self):\n",
    "        ''' Return the percent of exploration of chemical space'''\n",
    "        return len(self.explored_space_index)/self.space_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of chemical space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Exploration of chemical space\n",
    "class Simulation():\n",
    "    def __init__(self, model, data,method,screen_size,number_initial_data,test_print,max_iter):\n",
    "        self.data = data\n",
    "        self.chemspace = ChemicalSpace(data, )\n",
    "        self.method = method\n",
    "        self.screen_size = screen_size\n",
    "        self.max_real_yield = []\n",
    "        self.number_initial_data = number_initial_data\n",
    "        self.test_print = test_print\n",
    "        self.max_iter = max_iter \n",
    "        self.RMSE_mean = []\n",
    "        self.RMSE_sd = []\n",
    "        self.model = model\n",
    "        \n",
    " \n",
    "    \n",
    "    def explore_space(self): \n",
    "        \n",
    "        # define the model                 \n",
    "        model = self.model \n",
    "        \n",
    "        # randomly guess select k reactions from chemical space\n",
    "        random_guess = self.chemspace.random_guess(self.number_initial_data)        \n",
    "\n",
    "        # Evaluate average yield of selected reactions\n",
    "        self.max_real_yield = [np.mean(random_guess['Product_Yield_PCT_Area_UV'])]    \n",
    "        \n",
    "        # Evaluate the RMSE of the random selected reactions\n",
    "        X_train , y_train = shuffle(random_guess.drop('Product_Yield_PCT_Area_UV', axis=1),\n",
    "                                    random_guess['Product_Yield_PCT_Area_UV'])\n",
    "        cv_res = cross_validations_plots(self.model, X_train , y_train,n_splits = 4)\n",
    "        self.RMSE_mean.append(cv_res[\"CrossValMeans\"].values) \n",
    "        self.RMSE_sd.append(cv_res[\"CrossValerrors\"].values) \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        iteration = 1\n",
    "        best_idxs = []\n",
    "        \n",
    "        \n",
    "        while not self.chemspace.is_empty() and iteration < self.max_iter:\n",
    "        #while not self.chemspace.is_empty():\n",
    "            \n",
    "            # split data for reactions explored so far           \n",
    "            X_train , y_train = shuffle(self.chemspace.get_explored().drop('Product_Yield_PCT_Area_UV', axis=1),\n",
    "                                        self.chemspace.get_explored()['Product_Yield_PCT_Area_UV'])\n",
    "            \n",
    "            \n",
    "            #print(X_train.shape)\n",
    "            # train the random forest on this data\n",
    "            model.fit(X_train,y_train)\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            # Get a dataframe with all reaction which hasn't been performed\n",
    "            unseen = self.chemspace.get_unused()\n",
    "                        \n",
    "            X_unseen = unseen.drop('Product_Yield_PCT_Area_UV', axis=1).copy()\n",
    "            \n",
    "            \n",
    "            ##################################\n",
    "            # choose the exploration strategy#   \n",
    "            ##################################\n",
    "            \n",
    "            if (self.method == 'Labmate_Ai'):                \n",
    "                yp = model.predict(X_unseen)\n",
    "                unseen[self.method] = yp\n",
    "                sorted_by = unseen.sort_values(by=[self.method],ascending=False)\n",
    "                                                \n",
    "            if (self.method == 'expected_improvement_RF'):\n",
    "                #print(X_unseen.shape)\n",
    "                unseen[self.method] = expected_improvement_RF(model,X_unseen,X_train,y_train,xi=0.01)[self.method].values\n",
    "                sorted_by = unseen.sort_values(by=[self.method],ascending=False)\n",
    "\n",
    "            \n",
    "            if (self.method == 'probability_of_improvement'):\n",
    "                unseen[self.method] = probability_of_improvement(model,X_unseen,X_train,y_train)[self.method].values\n",
    "                sorted_by = unseen.sort_values(by=[self.method],ascending=False)\n",
    "                \n",
    "            if (self.method == \"random_search\"):\n",
    "                unseen.sample(n=len(unseen))\n",
    "                unseen[self.method] = unseen['Product_Yield_PCT_Area_UV'].values\n",
    "                sorted_by = unseen\n",
    "\n",
    "            if (self.method == \"upper_confidence_bound\"):\n",
    "                unseen[self.method] = upper_confidence_bound(model,X_unseen,X_train,y_train,beta=0.1)[self.method].values\n",
    "                sorted_by = unseen.sort_values(by=[self.method],ascending=False)\n",
    "                \n",
    "\n",
    "                    \n",
    "            # Get a dataframe with best candidates from method chosen.\n",
    "            best_results = sorted_by.head(self.screen_size)\n",
    "                        \n",
    "            # Get idxs of best candidates \n",
    "            best_results_idxs = list(best_results.index) \n",
    "            best_idxs = best_idxs + best_results_idxs    \n",
    "            \n",
    "            # Get idxs of best candidates \n",
    "            best_results_idxs = list(best_results.index) \n",
    "                                                            \n",
    "            # Evaluate real yiled of selected batch of reactions \n",
    "            f_star = np.mean(best_results['Product_Yield_PCT_Area_UV'])\n",
    "            self.max_real_yield.append(f_star)           \n",
    "            \n",
    "            \n",
    "            # Evaluate the RMSE of the selected batches so far\n",
    "            cv_res = cross_validations_plots(self.model,X_train , y_train,n_splits = 4)\n",
    "            self.RMSE_mean.append(cv_res[\"CrossValMeans\"].values) \n",
    "            self.RMSE_sd.append(cv_res[\"CrossValerrors\"].values) \n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            # Add the current batch of reactions to explored reactions so in the next iteration RF can be trained on updated data    \n",
    "            self.chemspace.update_explored_rxns(best_results_idxs)\n",
    "                        \n",
    "                \n",
    "          \n",
    "            if self.test_print == True:\n",
    "                if iteration % 10 == 0:\n",
    "                    print(f\" the yield at iteration {iteration} is {f_star}\")\n",
    "                    print(f\" X_train.shape : {X_train.shape} \")\n",
    "                    print(f\" X_test.shape  : {X_unseen.shape} \")\n",
    "            \n",
    "            iteration += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "                                    \n",
    "        # Create a data frame \n",
    "        stat_dataframe = pd.DataFrame()\n",
    "        stat_dataframe['avg_real_yield'] = self.max_real_yield  \n",
    "        stat_dataframe['RMSE_mean'] = self.RMSE_mean\n",
    "        stat_dataframe['RMSE_sd'] = self.RMSE_sd\n",
    "\n",
    "        return stat_dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing : \n",
    "- LAbmateAi  \n",
    "- upper bound \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations & Averaving   descriptors Vs OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulations(n_simu = 10):\n",
    "    test_print = False\n",
    "    max_iter = 20\n",
    "    screen_size = 5\n",
    "    number_initial_data = 5\n",
    "    model = RandomForestRegressor(300,n_jobs = -1)\n",
    "    \n",
    "    Av_labmateai_y = []\n",
    "    Av_ucb_y = []\n",
    "\n",
    "\n",
    "    Av_labmateai_rmse = []\n",
    "    Av_ucb_rmse = []\n",
    "    \n",
    "   \n",
    "    Av_labmateai_y_ohe = []\n",
    "    Av_ucb_y_ohe = []\n",
    "\n",
    "\n",
    "    Av_labmateai_rmse_ohe = []\n",
    "    Av_ucb_rmse_ohe = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    k = 1\n",
    "    t1 = time.time()\n",
    "    for _ in range(n_simu):\n",
    "        t = time.time()\n",
    "        print(f\" iteration {k}\")\n",
    "        \n",
    "        ########################\n",
    "        # descriptors\n",
    "        ########################\n",
    "        \n",
    "        # labmateai\n",
    "        method = \"Labmate_Ai\"\n",
    "        simulation_labmateai = Simulation(model,df_descr,method,screen_size,number_initial_data,test_print,max_iter)\n",
    "        stat_dataframe_labmateai = simulation_labmateai.explore_space()\n",
    "        avg_real_yield_labmateai = stat_dataframe_labmateai['avg_real_yield']\n",
    "        RMSE_mean_labmateai = stat_dataframe_labmateai['RMSE_mean']\n",
    "\n",
    "        # upper_confidence_bound\n",
    "        method = \"upper_confidence_bound\"\n",
    "        simulation_UCB = Simulation(model,df_descr,method,screen_size,number_initial_data,test_print,max_iter)\n",
    "        stat_dataframe_UCB = simulation_UCB.explore_space()\n",
    "        avg_real_yield_UCB = stat_dataframe_UCB['avg_real_yield']\n",
    "        RMSE_mean_UCB = stat_dataframe_UCB['RMSE_mean']\n",
    "\n",
    "        Av_labmateai_y.append(avg_real_yield_labmateai)\n",
    "        Av_ucb_y.append(avg_real_yield_UCB)        \n",
    "        \n",
    "        Av_labmateai_rmse.append(RMSE_mean_labmateai)\n",
    "        Av_ucb_rmse.append(RMSE_mean_UCB)        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ########################\n",
    "        # OHE\n",
    "        ########################\n",
    "        \n",
    "        \n",
    "        # labmateai\n",
    "        method = \"Labmate_Ai\"\n",
    "        simulation_labmateai = Simulation(model,data_ohe,method,screen_size,number_initial_data,test_print,max_iter)\n",
    "        stat_dataframe_labmateai = simulation_labmateai.explore_space()\n",
    "        avg_real_yield_labmateai_ohe = stat_dataframe_labmateai['avg_real_yield']\n",
    "        RMSE_mean_labmateai_ohe = stat_dataframe_labmateai['RMSE_mean']\n",
    "\n",
    "        # upper_confidence_bound\n",
    "        method = \"upper_confidence_bound\"\n",
    "        simulation_UCB = Simulation(model,data_ohe,method,screen_size,number_initial_data,test_print,max_iter)\n",
    "        stat_dataframe_UCB = simulation_UCB.explore_space()\n",
    "        avg_real_yield_UCB_ohe = stat_dataframe_UCB['avg_real_yield']\n",
    "        RMSE_mean_UCB_ohe = stat_dataframe_UCB['RMSE_mean']        \n",
    "        \n",
    "        \n",
    "        Av_labmateai_y_ohe.append(avg_real_yield_labmateai)\n",
    "        Av_ucb_y_ohe.append(avg_real_yield_UCB)\n",
    "                \n",
    "        Av_labmateai_rmse_ohe.append(RMSE_mean_labmateai)\n",
    "        Av_ucb_rmse_ohe.append(RMSE_mean_UCB)\n",
    "\n",
    "        print( \"time : \" + str(( time.time()-t)/60) + \" min\")\n",
    "            \n",
    "        k += 1\n",
    "        \n",
    "        \n",
    "    t2 = time.time()\n",
    "    print( \"time : \" + str((t2-t1)/60) + \" min\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    # descriptors    \n",
    "    av_labmateai_y = np.mean(np.array(Av_labmateai_y),axis =0)\n",
    "    av_ucb_y = np.mean(np.array(Av_ucb_y),axis =0)\n",
    "    av_labmateai_rmse = np.mean(np.array(Av_labmateai_rmse),axis =0)\n",
    "    av_ucb_rmse = np.mean(np.array(Av_ucb_rmse),axis =0)\n",
    "    \n",
    "    \n",
    "    # ohe \n",
    "    av_labmateai_y_ohe = np.mean(np.array(Av_labmateai_y_ohe),axis =0)\n",
    "    av_ucb_y_ohe = np.mean(np.array(Av_ucb_y_ohe),axis =0)    \n",
    "    av_labmateai_rmse_ohe = np.mean(np.array(Av_labmateai_rmse_ohe),axis =0)\n",
    "    av_ucb_rmse_ohe = np.mean(np.array(Av_ucb_rmse_ohe),axis =0)\n",
    "\n",
    "    \n",
    "    \n",
    "    ###############################################################    \n",
    "    # plot  : All strategies : yiels & RMSE averaging\n",
    "    ###############################################################    \n",
    "    \n",
    "    xfit = np.arange(number_initial_data,number_initial_data + max_iter*screen_size , screen_size)\n",
    "\n",
    "    plt.figure(figsize=(35,6))\n",
    "    plt.plot(xfit,av_labmateai_rmse, '-', label='RMSE labmateai descriptors')\n",
    "    plt.plot(xfit,av_ucb_rmse, '-', label='RMSE UCB descriptors')\n",
    "    plt.plot(xfit,av_labmateai_rmse_ohe, '-', label='RMSE labmateai ohe')\n",
    "    plt.plot(xfit,av_ucb_rmse_ohe, '-', label='RMSE UCB ohe')\n",
    "    \n",
    "    \n",
    "    plt.xlabel('Reactions')\n",
    "    plt.ylabel('The average of the updated RMSE after every selection ')\n",
    "    plt.legend()\n",
    "    plt.pause(0.1)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(35,6))\n",
    "    plt.plot(xfit,av_labmateai_y, '-', label='Average yield per batch : labmateai descriptors')\n",
    "    plt.plot(xfit,av_ucb_y, '-', label='Average yield per batch : UCB descriptors')\n",
    "    plt.plot(xfit,av_labmateai_y_ohe, '-', label='Average yield per batch : labmateai ohe')\n",
    "    plt.plot(xfit,av_ucb_y_ohe, '-', label='Average yield per batch : UCB ohe')\n",
    "    plt.xlabel('Reactions')\n",
    "    plt.ylabel('the Average of the Averages of true yield in every batch ')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " iteration 1\n"
     ]
    }
   ],
   "source": [
    "simulations(n_simu = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
